{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7fb54b61",
   "metadata": {},
   "source": [
    "---\n",
    "title: Dr. Timnit Gebru\n",
    "author: Bridget Ulian\n",
    "date: '2023-04-16'\n",
    "description: \"A discussion of Dr. Timnit Gebru and her work.\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6985bca4",
   "metadata": {},
   "source": [
    "# Dr. Timnit Gebru and Her Work\n",
    "\n",
    "## Section 1: Introduction\n",
    "\n",
    "In my time at Middlebury College, I have been lucky enough to take two classes that focus on ethics as they pertain to technology: Gender, Technology and Future with Professor Gupta and Politics of Virtual Realities with Professor Stanger. Readings either about or by Dr. Timnit Gebru were included in both classes’ curricula. Dr. Gebru is a computer scientist, an Ethiopian refugee who found political but not emotional asylum in the United States, and someone who has single-handedly pushed research on the ethics of Artificial Intelligence into entirely novel waters. \n",
    "\n",
    "Dr. Gebru’s current work is focused on the Distributed Artificial Intelligence Research Institute (or DAIR), a collective of multidisciplinary researchers who examine the outcomes of AI technology, particularly as it pertains to the African continent and African immigrants in the United States. She previously acted as Google’s co-lead of the Ethical Artificial Intelligence Team, a position which ended in contention when Google asked Dr. Gebru to not publish a paper examining the dangers of bias in large language models. Dr. Gebru claims she was fired; Google claims she resigned. Either way, Google faced extensive internal and external criticism in response.\n",
    "\n",
    "Dr. Gebru will be virtually visiting Middlebury College to give a lecture on bias and the social impacts of artificial intelligence, and more narrowly, will be visiting our class for a Q&A on Monday, April 24.  \n",
    "\n",
    "## Section 2: Dr. Gebru’s Talk\n",
    "\n",
    "Dr. Gebru’s talk at the conference on Computer Vision and Pattern Recognition 2020 focuses on aspects of bias in artificial intelligence less explored by many discussing the topic. I find her idea of a dominant group close to the money very interesting; it follows a theme I noticed in articles about Dr. Gebru, that she focuses on the power dynamics of AI rather than just the biases. She talks about how visibility isn’t inclusion, which can translate to an understanding that there is bias does not mean those biases disappear. \n",
    "\n",
    "It is easy for companies like Google or Amazon or Microsoft to put out a statement saying “we understand there is bias in our algorithms and datasets. We are working to diversify our datasets and hone our algorithms.” Doing the work is much more difficult and multifaceted. Dr. Gebru explains this very well, particularly in an example of Google attempting to diversify their facial recognition datasets. In doing so, Google put out advertisements asking for darker skinned people to join their dataset in a predatory manner. In a similar way, when developers came to realize gender recognition technology isn’t trained on trans people, they scraped YouTube for images of trans creators without notifying said creators. Furthermore, Dr. Gebru argues this harm towards marginalized people goes even deeper. Why is there a gender recognition system that categorizes based on a binary, socially-constructed idea anyways?\n",
    "\n",
    "The point is it takes a lot of work and time to understand the implications of different technologies. In a competitive, for-profit, industry, work and time are only worth cutting. Why would a company spend the time and resources hiring experts on biases and social implications of a technology when they could make millions of dollars and cut costs simply by sending the product to the public? To harness the power dynamic between for-profit corporations and marginalized individuals, educated experts and resources need to focus on social implications of technology. It is likely that ensuring corporations take the time and resources to hire experts will require government intervention.\n",
    "\n",
    "tl;dr Visibility isn’t inclusion, acknowledging biases and inequity in technology development does not solve the problem of said biases and inequity, it takes much more work and depth of research into implications of technology. \n",
    "\n",
    "\n",
    "## Section 3: Questions\n",
    "\n",
    "I have a few questions for Dr. Gebru, one which has plagued me since I wrote a paper for the Politics of Virtual Realities and one which is simply a curiosity. \n",
    "\n",
    "1. *Quote from Meredith Whittaker, the senior advisor on AI to the Federal Trade Commission: “What I am concerned about is the capacity for social control that [AI] gives to a few profit-driven corporations.”*\n",
    "Question: Do you think the government has the capacity to regulate the power dynamics between massive for-profit tech corporations and the individual citizen, particularly marginalized citizens? \n",
    "Would this have to be an international institution, or is it feasible for individual governments to have different regulations for tech corporations? \n",
    "\n",
    "2. \n",
    "Do you think if there were an industry-wide oath that all technologists should take, similar to the hippocratic oath, it could help mitigate some of the issues we see in technology? If yes, what would be in that oath? \n",
    "\n",
    "\n",
    "## Optional Section 4: an excerpt from the paper I wrote for Politics of Virtual Realities that inspired question 1\n",
    "\n",
    "To avoid re-enchantment with AI and to retain our human dignity and autonomy, government leaders must take initiative in discussing and questioning how AI fits into our current world; AI gone unchecked will not follow moral or ethical guidelines necessary in decision-making, particularly when it comes to governance. This is not a simple task, particularly at a time where competition is so fierce between the United States and China, two technological and economic superpowers. However, without this discussion, humans at all levels of life will promote AI to the superior thinker in our world. In doing so, humanity will give up its autonomy and dignity. Once artificial intelligence begins making decisions for humans and humans stop questioning the validity or ethical implications of said decisions, regaining human autonomy will be impossible. As Heidegger argues, the questioning of the essence of technology is necessary to avoid becoming a standing-reserve and to continue humanity’s progression. This questioning must start with world leaders, who have the experts and means available to understand the implications of artificial intelligence on us as human beings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e583757d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451] *",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
